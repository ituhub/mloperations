# ğŸ” ML Model Monitor Pro

<div align="center">

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![Status](https://img.shields.io/badge/Status-Production%20Ready-success.svg)

**Enterprise-grade ML model monitoring with drift detection, explainability & intelligent alerting**

[Features](#-features) â€¢ [Quick Start](#-quick-start) â€¢ [Documentation](#-documentation) â€¢ [Screenshots](#-screenshots)

</div>

---

## ğŸ¯ Purpose

ML Model Monitor Pro is a comprehensive machine learning monitoring platform designed to help data science and ML engineering teams:

- **Detect problems early** - Catch model degradation, data drift, and anomalies before they impact business outcomes
- **Understand predictions** - Explainable AI features help build trust with stakeholders
- **Respond faster** - Intelligent alerting with actionable recommendations
- **Maintain compliance** - Track model performance for regulatory requirements

## ğŸ’ Key Benefits

| Benefit | Description |
|---------|-------------|
| ğŸš¨ **Early Detection** | Catch issues before they impact customers. Reduce MTTR by up to 80% |
| ğŸ§  **Explainability** | Understand why models make specific predictions |
| âš¡ **Faster Response** | Actionable recommendations with every alert |
| ğŸ“Š **360Â° Visibility** | Performance, latency, drift, and data quality in one place |
| ğŸ”— **Easy Integration** | REST API, webhooks, Slack, email notifications |

## âœ¨ Features

### ğŸ“ˆ Performance Monitoring
- Real-time tracking of MAE, RMSE, RÂ², accuracy, precision, recall, F1
- Latency monitoring with SLA tracking (P50, P95, P99)
- Throughput analysis and prediction counts
- Resource utilization (CPU, memory)
- Historical trend visualization

### ğŸ”„ Data Drift Detection
- **Population Stability Index (PSI)** - Industry standard drift metric
- **Kolmogorov-Smirnov Test** - Statistical distribution comparison
- **Wasserstein Distance** - Earth Mover's Distance
- **Jensen-Shannon Divergence** - Symmetric KL divergence
- Feature-level and overall drift scoring
- Adaptive thresholds based on baseline

### ğŸ” Anomaly Detection
- Identify unusual predictions and out-of-distribution inputs
- Anomaly scoring with explanations
- Trend analysis (increasing/decreasing/stable)
- Configurable sensitivity thresholds

### ğŸ“‹ Data Quality Profiling
- Missing value detection
- Feature statistics (mean, std, min, max)
- Outlier detection rates
- Data freshness monitoring
- Overall quality scoring

### ğŸ§  Model Explainability
- **SHAP Integration** - SHapley Additive exPlanations
- **Permutation Importance** - Model-agnostic feature importance
- **Gradient-based Importance** - For neural networks
- Feature contribution tracking over time
- Global and local explanations

### ğŸš¨ Intelligent Alerting
- Multi-channel notifications (Slack, Email, Webhooks)
- Configurable alert rules and thresholds
- Alert deduplication and aggregation
- Cooldown periods to prevent alert fatigue
- Actionable recommendations with every alert

## ğŸš€ Quick Start

### Prerequisites
- Python 3.9+
- pip or conda

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/ml-monitor-pro.git
cd ml-monitor-pro

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run the dashboard
streamlit run app.py
```

Visit `http://localhost:8501` in your browser.

## ğŸ“ Project Structure

```
ml_monitor_platform_v2/
â”œâ”€â”€ app.py                      # Main Streamlit dashboard (enhanced UI)
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ README.md                   # This file
â”‚
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ core/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ drift_detector.py   # Drift detection engine (PSI, KS, Wasserstein)
â”‚       â”œâ”€â”€ model_explainer.py  # SHAP, permutation, gradient importance
â”‚       â”œâ”€â”€ performance_tracker.py  # Metrics, baselines, SLA tracking
â”‚       â””â”€â”€ alert_manager.py    # Multi-channel alerting
â”‚
â”œâ”€â”€ config/                     # Configuration files (optional)
â”‚   â”œâ”€â”€ models.yaml
â”‚   â””â”€â”€ alerts.yaml
â”‚
â””â”€â”€ tests/                      # Unit tests
    â””â”€â”€ test_*.py
```

## ğŸ“– How to Use

### 1. Monitor Model Health
Start at the **Overview** section to see the health status of all deployed models:
- ğŸŸ¢ **Healthy** - All metrics within normal range
- ğŸŸ¡ **Warning** - Some metrics showing drift or degradation
- ğŸ”´ **Critical** - Immediate attention required

### 2. Analyze Performance Trends
Use the **Performance** tab to track metrics over time:
- Look for upward trends in error metrics (MAE, RMSE)
- Monitor latency against SLA thresholds
- Check throughput patterns

### 3. Detect Data Drift
The **Drift Detection** tab shows:
- PSI scores for each feature (< 0.1 good, > 0.2 critical)
- Statistical tests (KS-test, Wasserstein distance)
- Which features have drifted

### 4. Investigate Anomalies
**Anomaly Detection** helps identify:
- Unusual predictions
- Out-of-distribution inputs
- Potential model issues

### 5. Understand Predictions
**Explainability** tab provides:
- Feature importance rankings
- Which features drive predictions
- Positive vs negative impacts

### 6. Respond to Alerts
**Alerts** tab shows active issues with:
- Severity levels (Critical, High, Medium, Low)
- Actionable recommendations
- Time to respond guidance

## ğŸ“Š Metric Thresholds Reference

| Metric | Good | Warning | Critical |
|--------|------|---------|----------|
| **PSI** | < 0.1 | 0.1 - 0.2 | > 0.2 |
| **Latency** | < 50ms | 50-100ms | > 100ms |
| **Anomaly Rate** | < 0.5% | 0.5-1% | > 1% |
| **Error Rate** | < 0.1% | 0.1-1% | > 1% |

## ğŸ”Œ Integration Options

### REST API
```python
# Log a prediction
POST /api/v1/predictions/{model_id}
{
  "features": {...},
  "prediction": 0.85,
  "timestamp": "2025-01-15T10:30:00Z"
}
```

### Webhook Notifications
```json
{
  "webhook_url": "https://your-server.com/alerts",
  "events": ["drift_detected", "performance_degradation", "sla_violation"]
}
```

### Slack Integration
```python
from backend.core.alert_manager import AlertManager, SlackNotificationChannel

alert_manager = AlertManager()
alert_manager.register_channel(
    "slack",
    SlackNotificationChannel(webhook_url="https://hooks.slack.com/...")
)
```

## ğŸ§ª Running Tests

```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=backend --cov-report=html
```

## ğŸ“ˆ Supported Model Types

| Framework | Support Level |
|-----------|--------------|
| Scikit-learn | âœ… Full |
| XGBoost | âœ… Full |
| LightGBM | âœ… Full |
| PyTorch | âœ… Full |
| TensorFlow/Keras | âœ… Full |
| Custom Models | âœ… Via predict() interface |

## ğŸ—ºï¸ Roadmap

- [ ] A/B testing support
- [ ] Automated retraining triggers
- [ ] MLflow integration
- [ ] Kubernetes deployment templates
- [ ] Real-time streaming (Kafka, Kinesis)
- [ ] Custom metric plugins
- [ ] Multi-tenant support

## ğŸ¤ Contributing

Contributions are welcome! Please read our [Contributing Guide](CONTRIBUTING.md) for details.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Built with [Streamlit](https://streamlit.io/)
- Explainability powered by [SHAP](https://github.com/slundberg/shap)
- Charts by [Plotly](https://plotly.com/)

---

<div align="center">

**Made with â¤ï¸ for the ML community**

[â¬† Back to Top](#-ml-model-monitor-pro)

</div>
